---
description: Terminology and resources at a glance
icon: bullseye-arrow
---

# Understanding the AI landscape

{% hint style="info" %}
These are all random items, they are not sequential, I am just trying to map it all here.
{% endhint %}

### Finding models that you want

{% embed url="https://lmstudio.ai/" %}

### The Prompt Engineer

In AI, the prompt engineer designs and optimizes prompts for AI models to yield specific outputs. As AI improves, it requires precise prompts for desired results, dealing with human language ambiguity and balancing creativity with precision. Key challenges include minimizing biases from training data and understanding AI instruction interpretation. Skilled prompt engineers are critical as AI expands, aligning human intent with machine understanding and enhancing AI reliability

{% embed url="https://github.com/anthropics/prompt-eng-interactive-tutorial" %}

{% embed url="http://promptingguide.ai/" %}

### Mediapipe

Mediapipe is a versatile ML framework that simplifies the development and deployment of high-performance machine learning pipelines across multiple platforms, such as mobile, web, and edge devices. It features a range of pre-trained models ideal for tasks like object detection, hand tracking, and pose estimation. Mediapipeâ€™s modular design allows for easy customization and integration of custom models, optimizing resources for real-time applications. Its cross-platform capabilities enable developers to efficiently build, test, and deploy advanced computer vision functionalities and enhance applications in fields like AR/VR, healthcare, and

{% embed url="https://www.youtube.com/watch?v=AkgDid5oYFM" %}



### Understanding Function Calling in LLM

Function calling in language models is a crucial feature that enhances interactivity and user engagement. In essence, it allows language models (LLMs) to execute predefined functions based on user input or specific triggers.

#### Key Concepts

1. **Function Invocation**: This process requires the language model to recognize a particular user command or pattern within the input and call the corresponding function to execute the desired task.
2. **Predefined Functions**: These are the functions encapsulated within the environment of the LLM, designed to perform specific tasks such as fetching data, calculations, or automating repetitive tasks. They must be well-defined and accessible to the model.
3. **Interactivity**: One of the main objectives of function calling in LLMs is to increase the model's interactivity, allowing it to perform real-time actions beyond simple text generation, thereby making the interaction more dynamic and responsive.
4. **Error Handling**: Ensuring that the model handles potential errors gracefully is crucial. This involves checking for invalid inputs, handling exceptions, and providing meaningful error messages to guide the user.
5. **Use Cases**: Function calling can be applied in various contexts, such as chatbots answering queries by pulling information from databases, virtual assistants setting reminders, or even complex data analysis on-the-fly based on user requests.

{% embed url="https://www.youtube.com/watch?v=3Vsusi9wmqY" %}

### Using Gemma on Android

Gemma on Android brings advanced language processing capabilities directly to mobile devices, leveraging the power of language models in a portable format. By deploying Gemma on Android, users can interact with a highly responsive and interactive AI system, capable of performing complex tasks such as data analysis, reminders, and real-time information retrieval. The integration with Android applications through Termex allows seamless operation of Gemma 3n, providing developers and users with a robust tool for enhancing mobile applications' functionality and user experience. This deployment empowers Android devices with the same cutting-edge AI capabilities usually reserved for desktop or cloud-based applications.

{% embed url="https://aashi-dutt3.medium.com/part-1-step-by-step-dataset-creation-unstructured-to-structured-70abdc98abf0" %}

{% embed url="https://aashi-dutt3.medium.com/part-2-fine-tune-gemma-2b-it-model-a26246c530e7" %}

{% embed url="https://medium.com/google-developer-experts/part-3-deploy-gemma-on-android-5bac532c54b7" %}

Issue with bits and bytes need to find alternative resource.

{% embed url="https://www.youtube.com/watch?v=DbwWEt32CJU" %}

{% embed url="https://medium.com/@magesh27/simple-react-app-ui-to-connect-with-local-gemma-model-via-lm-studio-c746c8a996f5" %}



### Gemma 3n on mobile

Using Termex to run Gemma 3

{% embed url="https://www.youtube.com/watch?v=C6ZNXrD0xVU" %}

## Finetuning

why?

Finetuning is the process of taking a pre-trained machine learning model and further training it on a specific task or dataset to improve its performance for that task. This is often done to leverage the general knowledge the model has already acquired and adapt it to new, more specific requirements. By finetuning, you can enhance the accuracy and efficiency of the model in real-world applications, allowing it to produce better results tailored to your specific needs.

Using MLX

{% embed url="https://www.youtube.com/watch?v=3UQ7GY9hNwk" %}

Using Axolotl

Using PEFT



Using Unsloth

{% embed url="https://github.com/vossenwout/llm-finetuning-resources" %}

{% embed url="https://www.youtube.com/watch?v=Lt7KrFMcCis&t=120s" %}

<figure><img src="../.gitbook/assets/image.png" alt=""><figcaption></figcaption></figure>

<figure><img src="../.gitbook/assets/image (1).png" alt=""><figcaption></figcaption></figure>

<figure><img src="../.gitbook/assets/image (2).png" alt=""><figcaption></figcaption></figure>

### Using mediapipe

{% embed url="https://www.youtube.com/watch?v=NiK5wHce03Y&list=PLOU2XLYxmsILVnjfBvtTWZC4YiHBwz-4l&index=11" %}



